---
title: "eds213 Data Cleaning assignment"
author: Michelle Yiv
format: html
editor: visual
---

## Background

Data about shorebird ecology and the environment were collected from 16 field sites in Alaska, Canada, and Russia from 1993-2014

## Setup: Load libraries and read in data

```{r}
#| message: false  

# Load libraries
library(tidyverse)
library(stringr)
library(naniar)
library(here)

# Load file path
datadir_processed <- "data/processed/"

# Read in data
# Note that this CSV contains a corrected snow cover column generated by Julien during class

snowsurvey_csv <- read_csv(here("data", "processed", "snow_cover.csv"))
```

## Data exploration

```{r}
# View the data
glimpse(snowsurvey_csv)

# Note that water_cover and land_cover columns are chr
```

### Land_cover exploration and cleaning

According to the metadata, this is the percent cover of exposed land.

Total_cover column will also be referenced, which is the total sum (to check the above percents; should always sum to 100)

```{r}
# View the number of values in the column
snowsurvey_csv %>%
  count(Land_cover)

# Note there are negatives & decimals

```

```{r}
# Then look for any non-numeric values
snowsurvey_csv %>%
  count(Land_cover) %>%
  filter(is.na(as.numeric(Land_cover)))

# As seen here we have "n/a" and "unk" values, and 7 NA values
```

Let's deal with non numeric values first before tackling the negative values.

First, the easiest fix appears to be "n/a" as it should be regarded as a normal NA value.

```{r}
# Change n/a to NA
snowsurvey_fixed <- snowsurvey_csv %>% 
  mutate(Land_cover = ifelse(Land_cover == "n/a", NA, Land_cover))
```

It is probably safe to assume "unk" is another NA value, but lets check it against the other columns to make sure before making any changes

```{r}
# View unk in the df
snowsurvey_fixed %>% 
  filter(Land_cover == "unk")
# Snow cover value is also an NA, so let us change to NA
```

```{r}
# Change unk to NA
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "unk", NA, Land_cover))
```

Now let's look at the negative values: We have two: -100 and -298. Let's look at both of them in the df

```{r}
# View -100 in the df
snowsurvey_fixed %>% 
  filter(Land_cover == "-100") 
```

Total cover ends up being 100, and water_cover is 0 and snow cover is also NA. This could be a typo of someone accidentally pressing the minus sign.

Let's check this area during to see if there any noticeable patterns

```{r}
# Check the df for the same Location and plot
snowsurvey_fixed %>% 
  filter((Location == "d10")  & (Plot == "brw3"))
```

Nothing jumps out at me, so I prefer turning this value into NA rather than skewing the data

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "-100", NA, Land_cover))
```

```{r}
# View -100 in the df
snowsurvey_fixed %>% 
  filter(Land_cover == "-298")
```

There is a value for snow cover, but the value for land cover appears to be automatically generated to fit the rule of total_cover being 100. From this, it is hard to distinguish whether the value for Water_cover was meant to be 53 or 35. Because of this, I will also choose to turn this value into NA.

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "-298", NA, Land_cover))
```

Let's make sure that all values were taken care of now:

```{r}
# Check for negative values
snowsurvey_fixed %>%
  count(Land_cover)
# All good here! Numbers range from 0-99
```

```{r}
# Check for non numeric values
snowsurvey_fixed %>%
  count(Land_cover) %>%
  filter(is.na(as.numeric(Land_cover)))

# All NA values! Yay!
```

Now lets transform this column into numeric!

```{r}
# Change to numeric type
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = as.numeric(Land_cover))
```

And check no values exceed 100 and are below zero

```{r}
# Check values 0-100
snowsurvey_fixed %>% 
  filter((Land_cover > 100) | (Land_cover < 0)) 
```

Yay! Now let's look at the water_cover column

### Water_cover exploration and cleaning

Like with land_cover, let's look for values that do not fall between 0 and 100

```{r}
# View the number of values in the column
snowsurvey_fixed %>%
  count(Water_cover)

# There are no negative values!
```

```{r}
# Check for non-numeric values
snowsurvey_fixed %>%
  count(Water_cover) %>%
  filter(is.na(as.numeric(Water_cover)))
```

We have some "n/a" values and an "unk" value.

"n/a" is a straightforward assumption to NA value, so let's change it here

```{r}
# Change n/a to NA
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "n/a", NA, Water_cover))
```

Now let's look at the "unk" in the data

```{r}
snowsurvey_fixed %>% 
  filter(Water_cover == "unk") 
```

Snow cover and land cover value is also an NA, so let us change to NA

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "unk", NA, Water_cover))
```

That wraps up the fixes for the water_cover column. Let's double check all non numeric values were changed.

```{r}
snowsurvey_fixed %>% 
  count(Water_cover) %>%
  filter(is.na(as.numeric(Water_cover)))
```

Now let's transform this to numeric type

```{r}
# Change to numeric type
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = as.numeric(Water_cover))
```

And check that all values fall from 0-100

```{r}
# Check values 0-100
snowsurvey_fixed %>% 
  filter((Water_cover > 100) | (Water_cover < 0)) 
```

Oh no! This value is likely a typo, but we cannot tell what this value is supposed to be. Therefore, I will change this value to NA.

```{r}
# Change value to NA
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "353", NA, Water_cover))
```

```{r}
 # Check changes
snowsurvey_fixed %>%
  filter((Water_cover > 100) | (Water_cover < 0))
```

## Using the three cover columns to infer missing values

To properly infer missing values, two of the three cover columns should be filled to infer the last one. The metadata states that the total of the three columns should be 100

First, let's transform the total_cover column to be numeric.

```{r}
# Convert total cover to numeric
snowsurvey_fixed <- snowsurvey_fixed %>%
    mutate(Total_cover = as.numeric(Total_cover))
```

So, let's write this out. Whenever one of our variables is missing (NA value), subtract the other two variables from the total_cover column. As stated above, the total_cover column should add to 100.

```{r}
snowsurvey_fixed_inferred <- snowsurvey_fixed %>%
  mutate(
    Snow_cover = case_when(
      is.na(Snow_cover) ~ Total_cover - Land_cover - Water_cover,
      TRUE ~ Snow_cover
    ),
    Land_cover = case_when(
      is.na(Land_cover) ~ Total_cover - Snow_cover - Water_cover,
      TRUE ~ Land_cover
    ),
    Water_cover = case_when(
      is.na(Water_cover) ~ Total_cover - Snow_cover - Land_cover,
      TRUE ~ Water_cover
    ),
    Total_cover = case_when(
      is.na(Total_cover) ~ Snow_cover + Land_cover + Water_cover,
      TRUE ~ Total_cover
    ))
```

However, we did not check if ALL total_cover rows are 100. Let's check now

```{r}
snowsurvey_fixed_inferred %>%
  filter(Total_cover !=100)  %>%
  view() # Uncomment to view easier
```

Let's take a look at the breakdown of these returned values

```{r}
snowsurvey_fixed_inferred %>%
  count(Total_cover)
```

We have quite a few values that are not 100. Looking at the data, I found a few rows where you can infer that there was a simple typo (when two of three cover variables were available). However most of the rows were just the result of bad math. Therefore, I feel more comfortable dropping these rows at it is unclear how to find the actual value. A little under \~5000 rows will be changed, but considering the total number of over 42000 observations, I make the assumption that this will not significantly impact the results.

```{r}
# Change values not 100 in Tota_cover to NA

snowsurvey_fixed_inferred <- snowsurvey_fixed_inferred %>%
  mutate(Total_cover = ifelse(Total_cover != 100, NA, Total_cover))
```

```{r}
# Check changes
snowsurvey_fixed_inferred %>%
  filter(Total_cover != 100)
```

The dataframe is now fixed! Let's save this to a new csv file

```{r}
write_csv(snowsurvey_fixed_inferred, file.path(datadir_processed, "snow_cover_fixed_MichelleYiv.csv"))
```
